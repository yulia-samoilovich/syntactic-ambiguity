{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e09a8ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/a9/cc/f2bbce0ad52e09cd1aecb724af06385021b42a7317cd5938ba9c8581509d/openai-1.13.3-py3-none-any.whl.metadata\n",
      "  Downloading openai-1.13.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/yuliasamoilovich/anaconda3/lib/python3.11/site-packages (from openai) (3.5.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Obtaining dependency information for distro<2,>=1.7.0 from https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl.metadata\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Obtaining dependency information for httpx<1,>=0.23.0 from https://files.pythonhosted.org/packages/41/7b/ddacf6dcebb42466abd03f368782142baa82e08fc0c1f8eaa05b4bae87d5/httpx-0.27.0-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/yuliasamoilovich/anaconda3/lib/python3.11/site-packages (from openai) (1.10.8)\n",
      "Requirement already satisfied: sniffio in /Users/yuliasamoilovich/anaconda3/lib/python3.11/site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/yuliasamoilovich/anaconda3/lib/python3.11/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/yuliasamoilovich/anaconda3/lib/python3.11/site-packages (from openai) (4.7.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/yuliasamoilovich/anaconda3/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in /Users/yuliasamoilovich/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/2c/93/13f25f2f78646bab97aee7680821e30bd85b2ff0fc45d5fdf5393b79716d/httpcore-1.0.4-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-1.0.4-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Obtaining dependency information for h11<0.15,>=0.13 from https://files.pythonhosted.org/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl.metadata\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: h11, distro, httpcore, httpx, openai\n",
      "Successfully installed distro-1.9.0 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.13.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fb8b37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6409159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cohere\n",
      "  Obtaining dependency information for cohere from https://files.pythonhosted.org/packages/a4/49/6f9cae01e248bef4238525728cca006ca375eebc5874e6f246907f9baec9/cohere-4.53-py3-none-any.whl.metadata\n",
      "  Downloading cohere-4.53-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting tiktoken\n",
      "  Obtaining dependency information for tiktoken from https://files.pythonhosted.org/packages/9e/11/83ca4e19bb6fc15971e543725ae1269a8a1c133e55b5952801ab9c0bcc9e/tiktoken-0.6.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading tiktoken-0.6.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: aiohttp<4.0,>=3.0 in /Users/yuliasamoilovich/anaconda3/lib/python3.11/site-packages (from cohere) (3.8.5)\n",
      "Collecting backoff<3.0,>=2.0 (from cohere)\n",
      "  Obtaining dependency information for backoff<3.0,>=2.0 from https://files.pythonhosted.org/packages/df/73/b6e24bd22e6720ca8ee9a85a0c4a2971af8497d8f3193fa05390cbd46e09/backoff-2.2.1-py3-none-any.whl.metadata\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting fastavro<2.0,>=1.8 (from cohere)\n",
      "  Obtaining dependency information for fastavro<2.0,>=1.8 from https://files.pythonhosted.org/packages/45/35/ed6a09aa1bcaf3cf49f158ff6b7fa91cabe070f10e5d4f0618af8614c8c0/fastavro-1.9.4-cp311-cp311-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading fastavro-1.9.4-cp311-cp311-macosx_10_9_universal2.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: importlib_metadata<7.0,>=6.0 in /Users/yuliasamoilovich/anaconda3/lib/python3.11/site-packages (from cohere) (6.0.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /Users/yuliasamoilovich/anaconda3/lib/python3.11/site-packages (from cohere) (2.31.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /Users/yuliasamoilovich/anaconda3/lib/python3.11/site-packages (from cohere) (1.26.16)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/yuliasamoilovich/anaconda3/lib/python3.11/site-packages (from tiktoken) (2022.7.9)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/yuliasamoilovich/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0,>=3.0->cohere) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/yuliasamoilovich/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0,>=3.0->cohere) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/yuliasamoilovich/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/yuliasamoilovich/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/yuliasamoilovich/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0,>=3.0->cohere) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/yuliasamoilovich/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/yuliasamoilovich/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0,>=3.0->cohere) (1.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/yuliasamoilovich/anaconda3/lib/python3.11/site-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yuliasamoilovich/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.25.0->cohere) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yuliasamoilovich/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.25.0->cohere) (2023.11.17)\n",
      "Downloading cohere-4.53-py3-none-any.whl (52 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.6.0-cp311-cp311-macosx_11_0_arm64.whl (949 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m949.8/949.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading fastavro-1.9.4-cp311-cp311-macosx_10_9_universal2.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fastavro, backoff, tiktoken, cohere\n",
      "Successfully installed backoff-2.2.1 cohere-4.53 fastavro-1.9.4 tiktoken-0.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install cohere tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d40ae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbe84d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "open.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24478c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "  messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "  response = openai.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=messages,\n",
    "      temperature=0,\n",
    "  )\n",
    "  return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "616116e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_completion(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1748adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be90761f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Prompt: The employees knew the contract\n",
      "\n",
      "Generated Text:  inside and out, as they had spent hours reviewing and discussing it during their training sessions. They were well-versed in the terms and conditions, and were able to confidently answer any questions or concerns that arose from clients or colleagues. Their thorough understanding of the contract helped to ensure that all parties involved were on the same page and that the agreement was carried out smoothly and efficiently.\n",
      "\n",
      "Original Prompt: The mechanic accepted the car\n",
      "\n",
      "Generated Text:  and began inspecting it for any issues. He checked the engine, brakes, tires, and other components to ensure everything was in working order. After completing the inspection, he provided a list of recommended repairs and maintenance services to the car owner. The owner agreed to have the work done, and the mechanic got to work fixing the car. Once the repairs were completed, the car was returned to the owner in good condition, ready to hit the road again.\n",
      "\n",
      "Original Prompt: The old man recalled the nurse\n",
      "\n",
      "Generated Text:  who had cared for him during his stay at the hospital. She was a kind and gentle soul, always checking in on him and making sure he was comfortable. He remembered her soothing voice and the way she would hold his hand when he was feeling scared or in pain.\n",
      "\n",
      "As he sat in his rocking chair, reminiscing about the past, he couldn't help but feel grateful for the nurse who had been by his side during his time of need. She had been a ray of light in his darkest days, and he would never forget her kindness and compassion.\n",
      "\n",
      "The old man closed his eyes and said a silent prayer for the nurse, wherever she may be now. He hoped she was happy and healthy, knowing that she had made a lasting impact on his life. And as he drifted off to sleep, he whispered a heartfelt thank you to the nurse who had been his guardian angel in a time of need.\n",
      "\n",
      "Original Prompt: The traveller heard the clock\n",
      "\n",
      "Generated Text: ticking loudly in the empty room. The sound echoed off the walls, filling the space with a sense of urgency and unease. Each tick seemed to count down the moments until the traveller's departure, a reminder that time was slipping away.\n",
      "\n",
      "As the clock continued its relentless ticking, the traveller felt a sense of unease creeping over them. They couldn't shake the feeling that they were running out of time, that they needed to hurry before it was too late.\n",
      "\n",
      "With a sense of determination, the traveller gathered their belongings and headed out into the world, leaving the ticking clock behind. They knew that time was precious, and they were determined to make the most of every moment they had.\n",
      "\n",
      "Original Prompt: The journalist confirmed the story\n",
      "\n",
      "Generated Text: The journalist verified the accuracy of the story.\n",
      "\n",
      "Original Prompt: The worker maintained the walls\n",
      "\n",
      "Generated Text:  by regularly inspecting them for any cracks or damage, repairing any issues that were found, and applying a fresh coat of paint or sealant as needed. They also ensured that the walls were kept clean and free of debris to prevent any potential damage or deterioration. Additionally, the worker may have installed or repaired any necessary insulation or waterproofing to protect the walls from moisture and other environmental factors. Overall, the worker's diligent maintenance efforts helped to preserve the structural integrity and appearance of the walls.\n",
      "\n",
      "Original Prompt: The apprentice forgot the bicycle\n",
      "\n",
      "Generated Text: at the shop and had to walk home instead.\n",
      "\n",
      "Original Prompt: The committee mentioned the issue\n",
      "\n",
      "Generated Text:  during their meeting. They discussed possible solutions and decided to further investigate the matter before making a final decision. The issue was deemed important and urgent, and they agreed to prioritize it in their upcoming agenda. Members of the committee were tasked with gathering more information and presenting their findings at the next meeting. It was clear that the issue required prompt action and the committee was committed to addressing it effectively.\n",
      "\n",
      "Original Prompt: The army found the supplies\n",
      "\n",
      "Generated Text:  that had been hidden in a remote cave by the enemy. The discovery was a major victory for the troops, as the supplies included weapons, ammunition, and food that would have been used against them in battle. The army quickly secured the supplies and brought them back to their base, where they would be used to support their own operations. The successful mission was a testament to the skill and determination of the soldiers, who had worked tirelessly to track down the enemy's hidden cache. With the enemy's supplies now in their hands, the army was one step closer to achieving victory in the ongoing conflict.\n",
      "\n",
      "Original Prompt: The umpire warned the spectators\n",
      "\n",
      "Generated Text:  to refrain from using offensive language or behavior towards the players on the field. He reminded them that sportsmanship and respect are important values in the game of baseball. Any further misconduct could result in removal from the stadium.\n",
      "\n",
      "Original Prompt: The coach discovered the player\n",
      "\n",
      "Generated Text: had a natural talent for the sport and decided to recruit them onto the team.\n",
      "\n",
      "Original Prompt: The woman noticed the flyer\n",
      "\n",
      "Generated Text:  on the bulletin board as she walked past. It advertised a local charity event and she felt compelled to stop and read the details. The event was a fundraiser for a homeless shelter in the community, and they were looking for volunteers to help with various tasks. \n",
      "\n",
      "Feeling a sense of purpose and a desire to give back, the woman took a picture of the flyer on her phone and made a mental note to sign up to volunteer. She knew that even a small act of kindness could make a big difference in someone's life, and she was eager to do her part to help those in need.\n",
      "\n",
      "Original Prompt: The tourists saw the palace\n",
      "\n",
      "Generated Text:  in all its grandeur, with its towering spires and intricate carvings. They marveled at the opulence of the architecture and the rich history that surrounded the ancient building. As they walked through the ornate halls and lush gardens, they couldn't help but feel a sense of awe and wonder at the beauty of the palace. It was a truly unforgettable experience for the tourists, one that they would cherish for years to come.\n",
      "\n",
      "Original Prompt: The scientists proved the theory\n",
      "\n",
      "Generated Text:  through a series of carefully controlled experiments and observations. Their findings were consistent with the predictions of the theory, providing strong evidence to support its validity. The scientific community accepted the theory as a well-supported explanation for the phenomenon in question.\n",
      "\n",
      "Original Prompt: The soldiers remembered the town\n",
      "\n",
      "Generated Text:  they had passed through on their way to battle. It was a small, peaceful place with friendly locals who had welcomed them with open arms. They had shared meals and stories with the townspeople, and had even played games with the children in the square.\n",
      "\n",
      "As they marched away from the town, the soldiers couldn't help but feel a pang of sadness. They knew that they were heading into danger, and that some of them might not return. But the memory of the town and its people gave them hope and strength to carry on.\n",
      "\n",
      "Years later, when the war was over and the soldiers had returned home, they often spoke of the town with fondness. They remembered the kindness and generosity of the people there, and how it had helped them through the darkest days of battle.\n",
      "\n",
      "The town may have been just a brief stop on their journey, but it had left a lasting impression on the soldiers. They would never forget the warmth and hospitality they had experienced there, and it would always hold a special place in their hearts.\n",
      "\n",
      "Original Prompt: The priest recognized two guests\n",
      "\n",
      "Generated Text: who had arrived at the church for the Sunday service. He greeted them warmly and invited them to take a seat in the front row. As the service began, the priest noticed that the two guests were paying close attention to his sermon and nodding in agreement with his words.\n",
      "\n",
      "After the service, the priest approached the two guests and introduced himself. They introduced themselves as John and Mary, a couple who had recently moved to the area and were looking for a new church to attend. The priest was delighted to welcome them to the congregation and invited them to join the church community for coffee and fellowship after the service.\n",
      "\n",
      "As John and Mary chatted with other members of the congregation, the priest couldn't help but feel a sense of joy and gratitude for the new guests who had found their way to his church. He knew that they would be a valuable addition to the community and looked forward to getting to know them better in the weeks and months to come.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Prompt: The reporter revealed the politician\n",
      "\n",
      "Generated Text: The reporter revealed that the politician had been involved in a corruption scandal, accepting bribes in exchange for political favors. The politician denied the allegations, but the evidence presented by the reporter was damning. The story sent shockwaves through the political world, leading to calls for the politician to resign and face legal consequences for their actions.\n",
      "\n",
      "Original Prompt: The owners insured the house\n",
      "\n",
      "Generated Text:  against fire, theft, and other potential damages.\n",
      "\n",
      "Original Prompt: The lawyer established the alibi\n",
      "\n",
      "Generated Text: for his client by presenting evidence that showed the client was out of town at the time of the crime.\n",
      "\n",
      "Original Prompt: The store guaranteed the television\n",
      "Generated Text:  for one year against any defects or malfunctions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_prompt(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        max_tokens=500,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "with open(\"dataset.txt\") as phrases_file, open(\"no_cue_prompts.txt\") as prompts_file:\n",
    "    phrases = phrases_file.readlines()\n",
    "    prompts = prompts_file.readlines()\n",
    "        \n",
    "    for prompt in prompts: \n",
    "        generated_text = get_prompt(prompt)\n",
    "        print(f\"No Cue Prompt: {prompt}\")\n",
    "        print(f\"Generated Text: {generated_text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aa78ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
